apply plugin: 'scala'
apply plugin: 'eclipse'
apply plugin: 'idea'

apply from: 'gradle/tools.gradle'
apply from: 'gradle/information-online.gradle'

sourceCompatibility = 1.8
version = '1.0'
description = "Apache Spark + Hadoop meetup group. Intro workshop Apr 20"

def scalaVersion = '2.10.5'
def sparkVersion = '1.3.1'
def hadoopVersion = '2.6'

def sparkLibPath = "$projectDir/tools/spark-$sparkVersion-bin-hadoop$hadoopVersion/lib"
def scalaLibPath = "$projectDir/tools/scala-jars"
repositories {
    flatDir {
        dirs sparkLibPath, scalaLibPath
    }
    jcenter()
}

configurations {
    idea {
        transitive = true
    }
}

dependencies {
    // this will download scala for you
    compile "org.scala-lang:scala-library:$scalaVersion"
    idea "org.scala-lang:scala-library:$scalaVersion"
    idea "org.scala-lang:scala-compiler:$scalaVersion"
    idea "org.scala-lang:scala-reflect:$scalaVersion"

    // Add support for the unsupported scalaConsole gradle task
    // compile "org.scala-lang:jline:$scalaVersion"

    // this is the standalone jar for most spark projects
    compile files(sparkLibPath + "/spark-assembly-$sparkVersion-hadoop$hadoopVersion.0.jar") {
        builtBy 'extractSparkDistro'
    }

    // this is spark core - with all the transiative deps
    // compile "org.apache.spark:spark-core_$scalaMajorVersion:$sparkVersion"

    // optional: hadoop cluster
    // compile "org.apache.hadoop:hadoop-client:$hadoopVersion.0"

    // testCompile group: 'junit', name: 'junit', version: '4.11'
}

task prepareUsb {
    group 'preparation'
    description 'Download and Extract all the required tools and libraries for the USB stick'
    dependsOn(extractExampleData, extractSparkDistro, downloadAllIDEs)
}

task copyScalaJars(type: Copy) {
    from configurations.compile.files + configurations.idea.files
    into scalaLibPath
}
